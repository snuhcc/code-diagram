{
    "nodes": [
        {
            "id": "image_emotion_gender_demo.main",
            "function_name": "<module>",
            "file": "image_emotion_gender_demo.py",
            "line_start": 1,
            "line_end": 82,
            "description": "Top‚Äêlevel script executing the emotion and gender detection pipeline."
        }
    ],
    "edges": [
        {
            "id": "e0",
            "source": "image_emotion_gender_demo.main",
            "target": "utils.datasets.get_labels"
        },
        {
            "id": "e1",
            "source": "image_emotion_gender_demo.main",
            "target": "utils.datasets.get_labels"
        },
        {
            "id": "e2",
            "source": "image_emotion_gender_demo.main",
            "target": "utils.inference.load_detection_model"
        },
        {
            "id": "e3",
            "source": "image_emotion_gender_demo.main",
            "target": "keras.models.load_model"
        },
        {
            "id": "e4",
            "source": "image_emotion_gender_demo.main",
            "target": "keras.models.load_model"
        },
        {
            "id": "e5",
            "source": "image_emotion_gender_demo.main",
            "target": "utils.inference.load_image"
        },
        {
            "id": "e6",
            "source": "image_emotion_gender_demo.main",
            "target": "utils.inference.load_image"
        },
        {
            "id": "e7",
            "source": "image_emotion_gender_demo.main",
            "target": "utils.inference.detect_faces"
        },
        {
            "id": "e8",
            "source": "image_emotion_gender_demo.main",
            "target": "utils.inference.apply_offsets"
        },
        {
            "id": "e9",
            "source": "image_emotion_gender_demo.main",
            "target": "utils.inference.apply_offsets"
        },
        {
            "id": "e10",
            "source": "image_emotion_gender_demo.main",
            "target": "cv2.resize"
        },
        {
            "id": "e11",
            "source": "image_emotion_gender_demo.main",
            "target": "cv2.resize"
        },
        {
            "id": "e12",
            "source": "image_emotion_gender_demo.main",
            "target": "utils.preprocessor.preprocess_input"
        },
        {
            "id": "e13",
            "source": "image_emotion_gender_demo.main",
            "target": "numpy.expand_dims"
        },
        {
            "id": "e14",
            "source": "image_emotion_gender_demo.main",
            "target": "numpy.argmax"
        },
        {
            "id": "e15",
            "source": "image_emotion_gender_demo.main",
            "target": "utils.preprocessor.preprocess_input"
        },
        {
            "id": "e16",
            "source": "image_emotion_gender_demo.main",
            "target": "numpy.expand_dims"
        },
        {
            "id": "e17",
            "source": "image_emotion_gender_demo.main",
            "target": "numpy.expand_dims"
        },
        {
            "id": "e18",
            "source": "image_emotion_gender_demo.main",
            "target": "numpy.argmax"
        },
        {
            "id": "e19",
            "source": "image_emotion_gender_demo.main",
            "target": "utils.inference.draw_bounding_box"
        },
        {
            "id": "e20",
            "source": "image_emotion_gender_demo.main",
            "target": "utils.inference.draw_text"
        },
        {
            "id": "e21",
            "source": "image_emotion_gender_demo.main",
            "target": "utils.inference.draw_text"
        },
        {
            "id": "e22",
            "source": "image_emotion_gender_demo.main",
            "target": "cv2.cvtColor"
        },
        {
            "id": "e23",
            "source": "image_emotion_gender_demo.main",
            "target": "cv2.imwrite"
        }
    ]
}